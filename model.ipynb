{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddfcbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# sns.set(style=\"whitegrid\")\n",
    "import warnings \n",
    "from sklearn.svm import SVC, NuSVC\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors  import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "# from tflearn.data_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import interp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "#from keras.utils import to_categorical\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d34ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7092a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Renamed_feature= []\n",
    "for i in range(8):\n",
    "  #for renaming dataset of columns features F1 -- F8 \n",
    "  Renamed_feature.append('F'+str(i+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef96bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'F1':data.iloc[:,:8].values[:,0],\n",
    "                     'F2':data.iloc[:,:8].values[:,1],\n",
    "                     'F3':data.iloc[:,:8].values[:,2],\n",
    "                     'F4':data.iloc[:,:8].values[:,3],\n",
    "                     'F5':data.iloc[:,:8].values[:,4],\n",
    "                     'F6':data.iloc[:,:8].values[:,5],\n",
    "                     'F7':data.iloc[:,:8].values[:,6],\n",
    "                     'F8':data.iloc[:,:8].values[:,7],\n",
    "                     'Outcome':data.iloc[:,8:].values[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6500b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this  function is for algorithm based feature selection \n",
    "def feature_Selector(data, algo, n_feature):\n",
    "    \n",
    "    if algo=='PCA':                                                   #for pca algorithm\n",
    "        X_Data= data.iloc[:,:8].values\n",
    "        pca = PCA(n_components=n_feature)                             #number of feature\n",
    "        X_Data = pca.fit_transform(X_Data)\n",
    "        return X_Data , data.iloc[:,8:].values\n",
    "\n",
    "    if algo == 'ICA':\n",
    "        X_Data= data.iloc[:,:8].values\n",
    "        ICA = FastICA(n_components=n_feature, random_state=12) \n",
    "        X_Data = ICA.fit_transform(X_Data)\n",
    "        return X_Data , data.iloc[:,8:].values\n",
    "    \n",
    "    if algo =='corr':                                                   #for ica algorithm\n",
    "        if n_feature ==4:\n",
    "            data = data[['F2','F5','F4','F6','Outcome']]                #for 4 feature\n",
    "            return data.iloc[:,:4].values, data.iloc[:,4:].values\n",
    "        if n_feature ==6:\n",
    "            data = data[['F1','F2','F4','F5','F6','F8','Outcome']]       #for 6 feature\n",
    "            return data.iloc[:,:6].values, data.iloc[:,6:].values\n",
    "        \n",
    "    if algo == 'None':\n",
    "        return data.iloc[:,:8].values, data.iloc[:,8:].values            #if feature selection is off all features are counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63e8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function  is for manual outleir rejection\n",
    "def Manual (data):\n",
    "\n",
    "    # input dataset is data \n",
    "    max_Pregnancies = data.F1.max()                         #maximum feature of F1\n",
    "    data = data[data.F1!=max_Pregnancies]                   #find  where extreme value is absent and remove extreme\n",
    "    max_Glucose = data.F2.max()                             #maximum feature of F2  \n",
    "    data = data[data.F2!=max_Glucose]                       #find  where extreme value is absent and remove\n",
    "    for i in range(4):                                      #in this loop we succesively remove 4 minimum element \n",
    "      min_Glucose = data.F2.min()                           #find minimum\n",
    "      data = data[data.F2!=min_Glucose]                     #reject minimum\n",
    "    max_BloodPressure = data.F3.max()                       #maximum feature of F3\n",
    "    data = data[data.F3!=max_BloodPressure]                 #find  where extreme value is absent and remove\n",
    "    for i in range(2):                                      #in this loop we succesively remove 2 extreme element  \n",
    "      max_skinthickness = data.F4.max() \n",
    "      data = data[data.F4!=max_skinthickness]\n",
    "    for i in range(25):                                     #in this loop we succesively remove 25 extreme element  \n",
    "      max_Insulin = data.F5.max() \n",
    "      data = data[data.F5!=max_Insulin]\n",
    "    max_bmi = data.F6.max()\n",
    "    data = data[data.F6!=max_bmi]\n",
    "    for i in range(4):                                      #in this loop we succesively remove 4 minimum element  \n",
    "      min_bmi = data.F6.min() \n",
    "      data = data[data.F6!=min_bmi]\n",
    "    for i in range(20):                                     #in this loop we succesively remove 20 extreme element \n",
    "      max_DiabetesPedigreeF = data.F7.max()\n",
    "      data = data[data.F7!=max_DiabetesPedigreeF]\n",
    "    for i in range(20):                                     #in this loop we succesively remove 20 extreme element  \n",
    "      max_age = data.F8.max() \n",
    "      data = data[data.F8!=max_age]\n",
    "      df =data\n",
    "    return data\n",
    "\n",
    "# this function if for outlair rejection with respect to mean value\n",
    "def IQR_Mean (data):\n",
    "\n",
    "  for i in range(8): \n",
    "    x = data[Renamed_feature[i]]\n",
    "    Q1 = x.quantile(0.25)                                   # Q1 is the \"middle\" value in the first half of the rank-ordered data set.\n",
    "    Q3 = x.quantile(0.75)                                   # Q3 is the \"middle\" value in the second half of the rank-ordered data set.\n",
    "    IQR = Q3-Q1                                             # The interquartile range is equal to Q3 minus Q1.\n",
    "    mean = x.mean()                                         #mean of feature \n",
    "    for j in range(569):                                    # loop for first 569 elements of feature\n",
    "      temp = x[j]                                           # every feature value\n",
    "      LW = (Q1 - 1.5 * IQR)                                 #lower considerable range of gaussian distribution\n",
    "      UW = (Q3 + 1.5 * IQR)                                 #upper considerable range of gaussian distribution\n",
    "      if temp < LW:                                         #replace upper value with mean\n",
    "        x[j] = mean\n",
    "      if temp > UW:                                         #replace lower value with mean\n",
    "        x[j] = mean\n",
    "    data[Renamed_feature[i]] = x\n",
    "  return data\n",
    "\n",
    "############################################################\n",
    "# this function if for outlair rejection w.r.to median value same as previous function\n",
    "def IQR_Median (data): \n",
    "\n",
    "  for i in range(8):\n",
    "    x = data[Renamed_feature[i]]\n",
    "    Q1 = x.quantile(0.25)\n",
    "    Q3 = x.quantile(0.75)\n",
    "    IQR = Q3-Q1\n",
    "    median = x.quantile(0.5)                                # find the median\n",
    "    for j in range(569):                                    #replace the first 569 values with respect to median\n",
    "      temp = x[j]\n",
    "      LW = (Q1 - 1.5 * IQR)\n",
    "      UW = (Q3 + 1.5 * IQR)\n",
    "      if temp < LW:                                         #replace upper value with median\n",
    "        x[j] = median\n",
    "      if temp > UW:\n",
    "        x[j] = median                                       #replace upper value with median\n",
    "    data[Renamed_feature[i]] = x\n",
    "  return data\n",
    "\n",
    "# this function if for outlair rejection with 1.5 times of IQR that means that are significant in gaussian distribution\n",
    "def IQR (data):\n",
    "\n",
    "  #input dataset as data\n",
    "  for i in range(8):                                        # for every feature\n",
    "    Q1 = data[Renamed_feature[i]].quantile(0.25)\n",
    "    Q3 = data[Renamed_feature[i]].quantile(0.75)\n",
    "    IQR = Q3-Q1                                             #find IQR\n",
    "    LW = (Q1 - 1.5 * IQR)                                   #find lower boundary\n",
    "          # print(LW)\n",
    "    UW = (Q3 + 1.5 * IQR)                                   #find upper boundary\n",
    "          # print(UW)\n",
    "    data = data[data[Renamed_feature[i]]<UW]                #drop greater than upper limit\n",
    "    data = data[data[Renamed_feature[i]]>LW]                #drop smaller than lower limit\n",
    "\n",
    "  return data\n",
    "\n",
    "#outlier rejection with different condition\n",
    "def outlier_Rejection (data, iqr_Mean, iqr_Medain, iqr, manual):\n",
    "  # outlier_Rejection with conditional input\n",
    "  if iqr_Mean == True:                                     #reject outleir with Mean\n",
    "    data = IQR_Mean (data)\n",
    "  if iqr_Medain == True:                                   #reject outleir with Median\n",
    "    data = IQR_Median (data)\n",
    "  if iqr == True:                                          #reject outleir in IQR range\n",
    "    data = IQR (data)\n",
    "  if manual == True:                                       #reject outleir with manual\n",
    "    data = Manual (data)\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9fa92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Before Process: (768, 9)\n",
      "Shape After outlier Removed: (636, 9)\n"
     ]
    }
   ],
   "source": [
    "# Outlier rejection\n",
    "print('Shape Before Process: ' + str(data.shape))\n",
    "data = outlier_Rejection(data,\n",
    "                  iqr_Mean=False,\n",
    "                  iqr_Medain=False,\n",
    "                  iqr=True,\n",
    "                  manual=False)\n",
    "print('Shape After outlier Removed: ' + str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35571d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filling missing values\n",
    "def replace_zero(data, field, target):\n",
    "    mean_by_target = data.loc[data[field] != 0, [field, target]].groupby(target).mean()\n",
    "    data.loc[(data[field] == 0)&(data[target] == 0), field] = mean_by_target.iloc[0][0]\n",
    "    data.loc[(data[field] == 0)&(data[target] == 1), field] = mean_by_target.iloc[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710ead2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape After Filling Missing Value: (636, 9)\n"
     ]
    }
   ],
   "source": [
    "# filling missing values\n",
    "for col in ['F2', 'F3', 'F4', 'F5', 'F6']:   \n",
    "    replace_zero(data, col, 'Outcome')              \n",
    "print('Shape After Filling Missing Value: ' + str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18dba7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape After Feature Selection: (636, 6)\n"
     ]
    }
   ],
   "source": [
    "# algo parameters be - 'PCA','ICA','corr','None'\n",
    "X_Data,Y_Lavel = feature_Selector(data, algo='corr', n_feature=6)    \n",
    "print('Shape After Feature Selection: ' + str(X_Data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15bc10a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>171.474227</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>113.606695</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.059259</td>\n",
       "      <td>171.474227</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>27.094512</td>\n",
       "      <td>113.606695</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F1     F2    F3         F4          F5    F6     F7    F8  Outcome\n",
       "0  6.0  148.0  72.0  35.000000  171.474227  33.6  0.627  50.0        1\n",
       "1  1.0   85.0  66.0  29.000000  113.606695  26.6  0.351  31.0        0\n",
       "2  8.0  183.0  64.0  32.059259  171.474227  23.3  0.672  32.0        1\n",
       "3  1.0   89.0  66.0  23.000000   94.000000  28.1  0.167  21.0        0\n",
       "5  5.0  116.0  74.0  27.094512  113.606695  25.6  0.201  30.0        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9595763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.        , 148.        ,  35.        , 171.4742268 ,\n",
       "         33.6       ,  50.        ],\n",
       "       [  1.        ,  85.        ,  29.        , 113.60669456,\n",
       "         26.6       ,  31.        ],\n",
       "       [  8.        , 183.        ,  32.05925926, 171.4742268 ,\n",
       "         23.3       ,  32.        ],\n",
       "       ...,\n",
       "       [  5.        , 121.        ,  23.        , 112.        ,\n",
       "         26.2       ,  30.        ],\n",
       "       [  1.        , 126.        ,  32.05925926, 171.4742268 ,\n",
       "         30.1       ,  47.        ],\n",
       "       [  1.        ,  93.        ,  31.        , 113.60669456,\n",
       "         30.4       ,  23.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Data # 1,2,4,5,6,8 [BP,DPF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7eb3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Folds cross-validator\n",
    "random_initializer = 90\n",
    "kf = StratifiedKFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=random_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5aac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_Model (classifier, X_Train, Y_Train, tuned_parameters, verbose):\n",
    "    \n",
    "  clf = GridSearchCV(classifier,\n",
    "                    tuned_parameters,\n",
    "                    verbose=verbose,\n",
    "                    cv=5,\n",
    "                    scoring='roc_auc',\n",
    "                    n_jobs=-1)\n",
    "  clf.fit(X_Train, Y_Train)\n",
    "  return clf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6096829e",
   "metadata": {},
   "source": [
    "Accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_Data,Y_Lavel):   \n",
    "    \n",
    "    X_Train, X_Test = X_Data[train_index], X_Data[test_index]\n",
    "    Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]\n",
    "\n",
    "    tuned_parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.5, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "    xg = creat_Model (classifier = xgb.XGBClassifier(objective = \"binary:logistic\", eval_metric = 'error', random_state=random_initializer),\n",
    "                      X_Train = X_Train,\n",
    "                      Y_Train = Y_Train,\n",
    "                      tuned_parameters = tuned_parameters,\n",
    "                      verbose=True)\n",
    "    \n",
    "    Accuracy.append(accuracy_score(Y_Test, xg.predict(X_Test)))\n",
    "    print(\"Accuracy (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(Accuracy),np.std(Accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1bebabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Avg. +/- Std.) is  0.914 +/- 0.000\n",
      "Accuracy (Avg. +/- Std.) is  0.894 +/- 0.020\n",
      "Accuracy (Avg. +/- Std.) is  0.877 +/- 0.029\n",
      "Accuracy (Avg. +/- Std.) is  0.876 +/- 0.025\n",
      "Accuracy (Avg. +/- Std.) is  0.885 +/- 0.029\n"
     ]
    }
   ],
   "source": [
    "Accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_Data,Y_Lavel): \n",
    "    \n",
    "    X_Train, X_Test = X_Data[train_index], X_Data[test_index]\n",
    "    Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]\n",
    "    \n",
    "    tuned_parameters = { 'algorithm': ['SAMME','SAMME.R'],\n",
    "                       'learning_rate':[0.1,0.5,1.0],\n",
    "                       'n_estimators': [10,50,100,200]}\n",
    "\n",
    "    adb = creat_Model (classifier = AdaBoostClassifier( random_state=random_initializer),\n",
    "                      X_Train = X_Train,                                      # create a model using  AdaBoost Classifier\n",
    "                      Y_Train = Y_Train,\n",
    "                      tuned_parameters = tuned_parameters,\n",
    "                      verbose=0)\n",
    "\n",
    "    Accuracy.append(accuracy_score(Y_Test, adb.predict(X_Test)))\n",
    "    print(\"Accuracy (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(Accuracy),np.std(Accuracy))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f5ac99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Avg. +/- Std.) is  0.893 +/- 0.031\n"
     ]
    }
   ],
   "source": [
    "train_index, test_index = list(kf.split(X_Data,Y_Lavel))[0]\n",
    "X_Train, X_Test = X_Data[train_index], X_Data[test_index]\n",
    "Y_Train, Y_Test = Y_Lavel[train_index], Y_Lavel[test_index]\n",
    "tuned_parameters = { 'algorithm': ['SAMME','SAMME.R'],\n",
    "                       'learning_rate':[0.1,0.5,1.0],\n",
    "                       'n_estimators': [10,50,100,200]}\n",
    "\n",
    "adb = creat_Model (classifier = AdaBoostClassifier( random_state=random_initializer),\n",
    "                      X_Train = X_Train,                                      # create a model using  AdaBoost Classifier\n",
    "                      Y_Train = Y_Train,\n",
    "                      tuned_parameters = tuned_parameters,\n",
    "                      verbose=0)\n",
    "\n",
    "Accuracy.append(accuracy_score(Y_Test, xg.predict(X_Test)))\n",
    "print(\"Accuracy (Avg. +/- Std.) is  %0.3f +/- %0.3f\" %(np.mean(Accuracy),np.std(Accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8325ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(adb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "900893cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(kf.split(X_Data,Y_Lavel))[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b31e615",
   "metadata": {},
   "source": [
    "88 - 92.+ -1\n",
    "100 - 88.4 - 5\n",
    "90 - 93.8 - 1\n",
    "95 - 91.4 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d88dde01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.5'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e1612e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\bhuva\\anaconda3\\envs\\tensorflow\\lib\\site-packages (1.7.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\bhuva\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from xgboost) (1.9.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\bhuva\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from xgboost) (1.23.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eedc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
